{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from six.moves import cPickle as pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471, 391) (7662, 390)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
    "test_df = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
    "macro_df = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
    "train_df = pd.merge(train_df, macro_df, how='left', on='timestamp')\n",
    "test_df = pd.merge(test_df, macro_df, how='left', on='timestamp')\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# truncate the extreme values in price_doc #\n",
    "ulimit = np.percentile(train_df.price_doc.values, 99)\n",
    "llimit = np.percentile(train_df.price_doc.values, 1)\n",
    "train_df.loc[train_df['price_doc']>ulimit,'price_doc'] = ulimit\n",
    "train_df.loc[train_df['price_doc']<llimit,'price_doc'] = llimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove the special characters first\n",
    "try:\n",
    "    train_df.loc[train_df['child_on_acc_pre_school']== '#!','child_on_acc_pre_school'] = '0'\n",
    "    test_df.loc[test_df['child_on_acc_pre_school']== '#!','child_on_acc_pre_school'] = '0'\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rep_commas(a):\n",
    "    return a.replace(',','')\n",
    "\n",
    "train_df.child_on_acc_pre_school= train_df.child_on_acc_pre_school.fillna(0).astype(str).apply(rep_commas).astype(int)\n",
    "train_df.modern_education_share = train_df.modern_education_share.fillna(0).astype(str).apply(rep_commas).astype(int)\n",
    "train_df.old_education_build_share  =train_df.old_education_build_share.fillna(0).astype(str).apply(rep_commas).astype(int)\n",
    "test_df.child_on_acc_pre_school= test_df.child_on_acc_pre_school.fillna(0).astype(str).apply(rep_commas).astype(int)\n",
    "test_df.modern_education_share = test_df.modern_education_share.fillna(0).astype(str).apply(rep_commas).astype(int)\n",
    "test_df.old_education_build_share  =test_df.old_education_build_share.fillna(0).astype(str).apply(rep_commas).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_type\n",
      "sub_area\n",
      "culture_objects_top_25\n",
      "thermal_power_plant_raion\n",
      "incineration_raion\n",
      "oil_chemistry_raion\n",
      "radiation_raion\n",
      "railroad_terminal_raion\n",
      "big_market_raion\n",
      "nuclear_reactor_raion\n",
      "detention_facility_raion\n",
      "water_1line\n",
      "big_road1_1line\n",
      "railroad_1line\n",
      "ecology\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for f in train_df.columns:\n",
    "    if train_df[f].dtype=='object':\n",
    "        print(f)\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train_df[f].values.astype('str')) + list(test_df[f].values.astype('str')))\n",
    "        train_df[f] = lbl.transform(list(train_df[f].values.astype('str')))\n",
    "        test_df[f] = lbl.transform(list(test_df[f].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_count(df, group_col):\n",
    "    grouped_df = df.groupby(group_col)[\"id\"].aggregate(\"count\").reset_index()\n",
    "    grouped_df.columns = [group_col, \"count_\"+group_col]\n",
    "    df = pd.merge(df, grouped_df, on=group_col, how=\"left\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    df[\"null_count\"] = df.isnull().sum(axis=1)\n",
    "    df.fillna(-99, inplace=True)\n",
    "    \n",
    "    df.loc[df[\"build_year\"] == 0.0,\"build_year\"] = 2000.0\n",
    "    df.loc[df[\"build_year\"] == 20052009.0 ,\"build_year\"] = 2005.0\n",
    "    df.loc[df[\"build_year\"] == 215.0 ,\"build_year\"] = 2015.0\n",
    "    df.loc[df[\"build_year\"] == 4965.0 ,\"build_year\"] = 1965.0\n",
    "    df.loc[df[\"build_year\"] == 71.0 ,\"build_year\"] = 1971.0\n",
    "    df.loc[df[\"build_year\"] == 1.0 ,\"build_year\"] = 2001.0\n",
    "    df.loc[df[\"build_year\"] == 3.0 ,\"build_year\"] = 2003.0\n",
    "    df.loc[df[\"build_year\"] == 20.0 ,\"build_year\"] = 2000.0\n",
    "    df.loc[df[\"material\"] == 3.0,\"material\"] = 1.0\n",
    "    df.loc[((df[\"material\"] == 5.0) & (df[\"build_year\"] == -99.0)),\"build_year\"] = 1970.0\n",
    "    df.loc[((df[\"material\"] == 2.0 )& (df[\"build_year\"] == -99.0)),\"build_year\"] = 1965.0\n",
    "    df.loc[((df[\"material\"] == 4.0) & (df[\"build_year\"] == -99.0)),\"build_year\"] = 2016.0\n",
    "    df.loc[((df[\"material\"] == 6.0) & (df[\"build_year\"] == -99.0)),\"build_year\"] = 2016.0\n",
    "    df.loc[:,'male_f_p' ]= df.loc[:,'male_f']/np.maximum(df.loc[:,'full_all'],1)\n",
    "\n",
    "    df.loc[:,'young_all_p' ]= df.loc[:,'young_all']/np.maximum(df.loc[:,'full_all'],1)\n",
    "    df.loc[:,'young_male_p' ]= df.loc[:,'young_male']/np.maximum(df.loc[:,'full_all'],1)\n",
    "\n",
    "    df.loc[:,'work_all_p' ]= df.loc[:,'work_all']/np.maximum(df.loc[:,'full_all'],1)\n",
    "    df.loc[:,'work_male_p' ]= df.loc[:,'work_male']/np.maximum(df.loc[:,'full_all'],1)\n",
    "\n",
    "    df.loc[:,'ekder_all_p' ]= df.loc[:,'ekder_all']/np.maximum(df.loc[:,'full_all'],1)\n",
    "    df.loc[:,'ekder_male_p' ]= df.loc[:,'ekder_male']/np.maximum(df.loc[:,'full_all'],1)\n",
    "\n",
    "    df.loc[:,'0_6_all_p' ]= df.loc[:,'0_6_all']/np.maximum(df.loc[:,'full_all'],1)\n",
    "    df.loc[:,'0_6_male_p' ]= df.loc[:,'0_6_male']/np.maximum(df.loc[:,'full_all'],1)\n",
    "\n",
    "    df.loc[:,'7_14_all_p' ]= df.loc[:,'7_14_all']/np.maximum(df.loc[:,'full_all'],1)\n",
    "    df.loc[:,'7_14_male_p' ]= df.loc[:,'7_14_male']/np.maximum(df.loc[:,'full_all'],1)\n",
    "\n",
    "    df.loc[:,'0_17_all_p' ]= df.loc[:,'0_17_all']/np.maximum(df.loc[:,'full_all'],1)\n",
    "    df.loc[:,'0_17_male_p' ]= df.loc[:,'0_17_male']/np.maximum(df.loc[:,'full_all'],1)\n",
    "\n",
    "    df.loc[:,'16_29_all_p' ]= df.loc[:,'16_29_all']/np.maximum(df.loc[:,'full_all'],1)\n",
    "    df.loc[:,'16_29_male_p' ]= df.loc[:,'16_29_male']/np.maximum(df.loc[:,'full_all'],1)\n",
    "\n",
    "    df.loc[:,'0_13_all_p' ]= df.loc[:,'0_13_all']/np.maximum(df.loc[:,'full_all'],1)\n",
    "    df.loc[:,'0_13_male_p' ]= df.loc[:,'0_13_male']/np.maximum(df.loc[:,'full_all'],1)\n",
    "\n",
    "\n",
    "\n",
    "    # year and month #\n",
    "    df[\"yearmonth\"] = df[\"timestamp\"].dt.year*100 + df[\"timestamp\"].dt.month\n",
    "    # year and week #\n",
    "    df[\"yearweek\"] = df[\"timestamp\"].dt.year*100 + df[\"timestamp\"].dt.weekofyear\n",
    "    # year #\n",
    "    df[\"year\"] = df[\"timestamp\"].dt.year\n",
    "    # month of year #\n",
    "    df[\"month_of_year\"] = df[\"timestamp\"].dt.month\n",
    "    # week of year #\n",
    "    df[\"week_of_year\"] = df[\"timestamp\"].dt.weekofyear\n",
    "    # day of week #\n",
    "    df[\"day_of_week\"] = df[\"timestamp\"].dt.weekday\n",
    "    # ratio of living area to full area #\n",
    "    df[\"ratio_life_sq_full_sq\"] = df[\"life_sq\"] / np.maximum(df[\"full_sq\"].astype(\"float\"),1)\n",
    "\n",
    "    df.loc[df[\"ratio_life_sq_full_sq\"]<0,\"ratio_life_sq_full_sq\"] = 0\n",
    "    df.loc[df[\"ratio_life_sq_full_sq\"]>1,\"ratio_life_sq_full_sq\"] = 1\n",
    "    # ratio of kitchen area to living area #\n",
    "    df[\"ratio_kitch_sq_life_sq\"] = df[\"kitch_sq\"] / np.maximum(df[\"life_sq\"].astype(\"float\"),1)\n",
    "\n",
    "    df.loc[df[\"ratio_kitch_sq_life_sq\"]<0,\"ratio_kitch_sq_life_sq\"] = 0\n",
    "    df.loc[df[\"ratio_kitch_sq_life_sq\"]>1,\"ratio_kitch_sq_life_sq\"] = 1\n",
    "    # ratio of kitchen area to full area #\n",
    "    df[\"ratio_kitch_sq_full_sq\"] = df[\"kitch_sq\"] / np.maximum(df[\"full_sq\"].astype(\"float\"),1)\n",
    "\n",
    "    df.loc[df[\"ratio_kitch_sq_full_sq\"]<0,\"ratio_kitch_sq_full_sq\"] = 0\n",
    "    df.loc[df[\"ratio_kitch_sq_full_sq\"]>1,\"ratio_kitch_sq_full_sq\"] = 1\n",
    "    # floor of the house to the total number of floors in the house #\n",
    "    df[\"ratio_floor_max_floor\"] = df[\"floor\"] / df[\"max_floor\"].astype(\"float\")\n",
    "    \n",
    "    # num of floor from top #\n",
    "    df[\"floor_from_top\"] = df[\"max_floor\"] - df[\"floor\"]\n",
    "    df[\"extra_sq\"] = df[\"full_sq\"] - df[\"life_sq\"]\n",
    "    df[\"age_of_building\"] = df[\"build_year\"] -df[\"year\"]\n",
    "    df[\"ratio_preschool\"] = df[\"children_preschool\"] / df[\"preschool_quota\"].astype(\"float\")\n",
    "    df[\"ratio_school\"] = df[\"children_school\"] / df[\"school_quota\"].astype(\"float\")\n",
    "    df[\"ratio_preschool\"] = df[\"children_preschool\"] / df[\"preschool_quota\"].astype(\"float\")\n",
    "    df[\"ratio_school\"] = df[\"children_school\"] / df[\"school_quota\"].astype(\"float\")\n",
    "    df = add_count(df, \"yearmonth\")\n",
    "    df = add_count(df, \"yearweek\")\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = make_features(train_df)\n",
    "test_df = make_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_df.drop([\"id\",\"ID_metro\",\"ID_railroad_station_walk\",\"ID_railroad_station_avto\",\n",
    "                         \"ID_big_road1\",\"ID_big_road2\",\"ID_railroad_terminal\",\"ID_bus_terminal\",\n",
    "                         \"timestamp\",'male_f','female_f','young_all','young_male','young_female',\n",
    "                         'work_all','work_male','work_female','ekder_all','ekder_male','ekder_female',\n",
    "                         '0_6_all','0_6_male','0_6_female','7_14_all','7_14_male','7_14_female','0_17_all',\n",
    "                         '0_17_male','0_17_female','16_29_all','16_29_male','16_29_female','0_13_all',\n",
    "                         '0_13_male','0_13_female', \"price_doc\"], axis=1)\n",
    "test_X = test_df.drop([\"id\",\"ID_metro\",\"ID_railroad_station_walk\",\"ID_railroad_station_avto\",\n",
    "                         \"ID_big_road1\",\"ID_big_road2\",\"ID_railroad_terminal\",\"ID_bus_terminal\",\n",
    "                         \"timestamp\",'male_f','female_f','young_all','young_male','young_female',\n",
    "                         'work_all','work_male','work_female','ekder_all','ekder_male','ekder_female',\n",
    "                         '0_6_all','0_6_male','0_6_female','7_14_all','7_14_male','7_14_female','0_17_all',\n",
    "                         '0_17_male','0_17_female','16_29_all','16_29_male','16_29_female','0_13_all',\n",
    "                         '0_13_male','0_13_female'] , axis=1)\n",
    "\n",
    "train_y = np.log1p(train_df.price_doc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimized_GBM = GridSearchCV(xgb.XGBRegressor(**ind_params), cv_params, scoring = 'neg_mean_squared_error', cv = 5, n_jobs = -1) \n",
    "optimized_GBM.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(optimized_GBM.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
